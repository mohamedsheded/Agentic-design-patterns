{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1lRfJy3Esa01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8596ea4c-45d8-4fcc-a6d6-8a24a4ddbf55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n",
            "Downloading groq-0.16.0-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.7/109.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: colorama, groq\n",
            "Successfully installed colorama-0.4.6 groq-0.16.0\n"
          ]
        }
      ],
      "source": [
        "!pip install groq colorama"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "groq_api_key = userdata.get('groq_api_key')"
      ],
      "metadata": {
        "id": "nMvz7H839T94"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pprint import pprint\n",
        "from groq import Groq\n",
        "from IPython.display import display_markdown\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "from typing import Callable\n",
        "import time\n",
        "\n",
        "from colorama import Fore\n",
        "from colorama import Style\n",
        "\n",
        "from collections import deque\n",
        "from graphviz import Digraph\n"
      ],
      "metadata": {
        "id": "Jh65zaUl9T6j"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL = \"llama3-groq-70b-8192-tool-use-preview\"\n",
        "# MODEL = \"deepseek-r1-distill-llama-70b\"\n",
        "MODEL = \"llama-3.3-70b-versatile\"\n",
        "GROQ_CLIENT =  Groq(api_key=groq_api_key)"
      ],
      "metadata": {
        "id": "3kFil9OZ9kMZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Multi agent framework**"
      ],
      "metadata": {
        "id": "lUWjd3ev9aBy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**ReAct Agent Utils**"
      ],
      "metadata": {
        "id": "IMGrpZfBDH2w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Fancy prints**"
      ],
      "metadata": {
        "id": "yx2KfKNzO9-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fancy_print(message: str) -> None:\n",
        "    \"\"\"\n",
        "    Displays a fancy print message.\n",
        "\n",
        "    Args:\n",
        "        message (str): The message to display.\n",
        "    \"\"\"\n",
        "    print(Style.BRIGHT + Fore.CYAN + f\"\\n{'=' * 50}\")\n",
        "    print(Fore.MAGENTA + f\"{message}\")\n",
        "    print(Style.BRIGHT + Fore.CYAN + f\"{'=' * 50}\\n\")\n",
        "    time.sleep(0.5)\n"
      ],
      "metadata": {
        "id": "K27XAz3BPCc0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Completions from llm \"groq\"**"
      ],
      "metadata": {
        "id": "h2e5hG6aDVM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def completions_create(client, messages: list, model: str) -> str:\n",
        "    \"\"\"\n",
        "    Sends a request to the client's `completions.create` method to interact with the language model.\n",
        "\n",
        "    Args:\n",
        "        client (Groq): The Groq client object\n",
        "        messages (list[dict]): A list of message objects containing chat history for the model.\n",
        "        model (str): The model to use for generating tool calls and responses.\n",
        "\n",
        "    Returns:\n",
        "        str: The content of the model's response.\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(messages=messages, model=model)\n",
        "    return str(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "KPMOXpbWDKXi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Tool utils**"
      ],
      "metadata": {
        "id": "1GmAatPRDZLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_fn_signature(fn: Callable) -> dict:\n",
        "    \"\"\"\n",
        "    Generates the signature for a given function.\n",
        "\n",
        "    Args:\n",
        "        fn (Callable): The function whose signature needs to be extracted.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the function's name, description,\n",
        "              and parameter types.\n",
        "    \"\"\"\n",
        "    fn_signature: dict = {\n",
        "        \"name\": fn.__name__,\n",
        "        \"description\": fn.__doc__,\n",
        "        \"parameters\": {\"properties\": {}},\n",
        "    }\n",
        "    schema = {\n",
        "        k: {\"type\": v.__name__} for k, v in fn.__annotations__.items() if k != \"return\"\n",
        "    }\n",
        "    fn_signature[\"parameters\"][\"properties\"] = schema\n",
        "    return fn_signature\n",
        "\n",
        "\n",
        "def validate_arguments(tool_call: dict, tool_signature: dict) -> dict:\n",
        "    \"\"\"\n",
        "    Validates and converts arguments in the input dictionary to match the expected types.\n",
        "\n",
        "    Args:\n",
        "        tool_call (dict): A dictionary containing the arguments passed to the tool.\n",
        "        tool_signature (dict): The expected function signature and parameter types.\n",
        "\n",
        "    Returns:\n",
        "        dict: The tool call dictionary with the arguments converted to the correct types if necessary.\n",
        "    \"\"\"\n",
        "    properties = tool_signature[\"parameters\"][\"properties\"]\n",
        "\n",
        "    # TODO: This is overly simplified but enough for simple Tools.\n",
        "    type_mapping = {\n",
        "        \"int\": int,\n",
        "        \"str\": str,\n",
        "        \"bool\": bool,\n",
        "        \"float\": float,\n",
        "    }\n",
        "\n",
        "    for arg_name, arg_value in tool_call[\"arguments\"].items():\n",
        "        expected_type = properties[arg_name].get(\"type\")\n",
        "\n",
        "        if not isinstance(arg_value, type_mapping[expected_type]):\n",
        "            tool_call[\"arguments\"][arg_name] = type_mapping[expected_type](arg_value)\n",
        "\n",
        "    return tool_call\n",
        "\n",
        "\n",
        "class Tool:\n",
        "    \"\"\"\n",
        "    A class representing a tool that wraps a callable and its signature.\n",
        "\n",
        "    Attributes:\n",
        "        name (str): The name of the tool (function).\n",
        "        fn (Callable): The function that the tool represents.\n",
        "        fn_signature (str): JSON string representation of the function's signature.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, name: str, fn: Callable, fn_signature: str):\n",
        "        self.name = name\n",
        "        self.fn = fn\n",
        "        self.fn_signature = fn_signature\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.fn_signature\n",
        "\n",
        "    def run(self, **kwargs):\n",
        "        \"\"\"\n",
        "        Executes the tool (function) with provided arguments.\n",
        "\n",
        "        Args:\n",
        "            **kwargs: Keyword arguments passed to the function.\n",
        "\n",
        "        Returns:\n",
        "            The result of the function call.\n",
        "        \"\"\"\n",
        "        return self.fn(**kwargs)\n",
        "\n",
        "\n",
        "def tool(fn: Callable):\n",
        "    \"\"\"\n",
        "    A decorator that wraps a function into a Tool object.\n",
        "\n",
        "    Args:\n",
        "        fn (Callable): The function to be wrapped.\n",
        "\n",
        "    Returns:\n",
        "        Tool: A Tool object containing the function, its name, and its signature.\n",
        "    \"\"\"\n",
        "\n",
        "    def wrapper():\n",
        "        fn_signature = get_fn_signature(fn)\n",
        "        return Tool(\n",
        "            name=fn_signature.get(\"name\"), fn=fn, fn_signature=json.dumps(fn_signature)\n",
        "        )\n",
        "\n",
        "    return wrapper()"
      ],
      "metadata": {
        "id": "5cgppMm_DcNj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Extraction util**"
      ],
      "metadata": {
        "id": "6oOogRhaDk3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class TagContentResult:\n",
        "    \"\"\"\n",
        "    A data class to represent the result of extracting tag content.\n",
        "\n",
        "    Attributes:\n",
        "        content (List[str]): A list of strings containing the content found between the specified tags.\n",
        "        found (bool): A flag indicating whether any content was found for the given tag.\n",
        "    \"\"\"\n",
        "\n",
        "    content: list[str]\n",
        "    found: bool\n",
        "\n",
        "\n",
        "def extract_tag_content(text: str, tag: str) -> TagContentResult:\n",
        "    \"\"\"\n",
        "    Extracts all content enclosed by specified tags (e.g., , , etc.).\n",
        "\n",
        "    Parameters:\n",
        "        text (str): The input string containing multiple potential tags.\n",
        "        tag (str): The name of the tag to search for (e.g., 'thought', 'response').\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary with the following keys:\n",
        "            - 'content' (list): A list of strings containing the content found between the specified tags.\n",
        "            - 'found' (bool): A flag indicating whether any content was found for the given tag.\n",
        "    \"\"\"\n",
        "    # Build the regex pattern dynamically to find multiple occurrences of the tag\n",
        "    tag_pattern = rf\"<{tag}>(.*?)</{tag}>\"\n",
        "\n",
        "\n",
        "    # Use findall to capture all content between the specified tag\n",
        "    matched_contents = re.findall(tag_pattern, text, re.DOTALL)\n",
        "\n",
        "    # Return the dataclass instance with the result\n",
        "    return TagContentResult(\n",
        "        content=[content.strip() for content in matched_contents],\n",
        "        found=bool(matched_contents),\n",
        "    )"
      ],
      "metadata": {
        "id": "0kzp-NTcDnRe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Chat history utils**"
      ],
      "metadata": {
        "id": "-9LgRIzODrdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatHistory(list):\n",
        "    def __init__(self, messages: list | None = None, total_length: int = -1):\n",
        "        \"\"\"Initialise the queue with a fixed total length.\n",
        "\n",
        "        Args:\n",
        "            messages (list | None): A list of initial messages\n",
        "            total_length (int): The maximum number of messages the chat history can hold.\n",
        "        \"\"\"\n",
        "        if messages is None:\n",
        "            messages = []\n",
        "\n",
        "        super().__init__(messages)\n",
        "        self.total_length = total_length\n",
        "\n",
        "    def append(self, msg: str):\n",
        "        \"\"\"Add a message to the queue.\n",
        "\n",
        "        Args:\n",
        "            msg (str): The message to be added to the queue\n",
        "        \"\"\"\n",
        "        if len(self) == self.total_length:\n",
        "            self.pop(0)\n",
        "        super().append(msg)\n"
      ],
      "metadata": {
        "id": "6tlrzo4QDuF3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_chat_history(history: list, msg: str, role: str):\n",
        "    \"\"\"\n",
        "    Updates the chat history by appending the latest response.\n",
        "\n",
        "    Args:\n",
        "        history (list): The list representing the current chat history.\n",
        "        msg (str): The message to append.\n",
        "        role (str): The role type (e.g. 'user', 'assistant', 'system')\n",
        "    \"\"\"\n",
        "    history.append(build_prompt_structure(prompt=msg, role=role))\n"
      ],
      "metadata": {
        "id": "Bj1_GojcD1Dv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Prompt utils**"
      ],
      "metadata": {
        "id": "Y_OoY0JDD3jm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_prompt_structure(prompt: str, role: str, tag: str = \"\") -> dict:\n",
        "    \"\"\"\n",
        "    Builds a structured prompt that includes the role and content.\n",
        "\n",
        "    Args:\n",
        "        prompt (str): The actual content of the prompt.\n",
        "        role (str): The role of the speaker (e.g., user, assistant).\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary representing the structured prompt.\n",
        "    \"\"\"\n",
        "    if tag:\n",
        "        prompt = f\"<{tag}>{prompt}</{tag}>\"\n",
        "    return {\"role\": role, \"content\": prompt}"
      ],
      "metadata": {
        "id": "oiRHsOAkD7C0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "REACT_SYSTEM_PROMPT = \"\"\"\n",
        "You operate by running a loop with the following steps: Thought, Action, Observation.\n",
        "You are provided with function signatures within <tools></tools> XML tags.\n",
        "You may call one or more functions to assist with the user query. Don' make assumptions about what values to plug\n",
        "into functions. Pay special attention to the properties 'types'. You should use those types as in a Python dict.\n",
        "\n",
        "For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
        "\n",
        "<tool_call>\n",
        "{\"name\": <function-name>,\"arguments\": <args-dict>, \"id\": <monotonically-increasing-id>}\n",
        "</tool_call>\n",
        "\n",
        "Here are the available tools / actions:\n",
        "\n",
        "<tools>\n",
        "%s\n",
        "</tools>\n",
        "\n",
        "Example session:\n",
        "\n",
        "<question>What's the current temperature in Madrid?</question>\n",
        "<thought>I need to get the current weather in Madrid</thought>\n",
        "<tool_call>{\"name\": \"get_current_weather\",\"arguments\": {\"location\": \"Madrid\", \"unit\": \"celsius\"}, \"id\": 0}</tool_call>\n",
        "\n",
        "You will be called again with this:\n",
        "\n",
        "<observation>{0: {\"temperature\": 25, \"unit\": \"celsius\"}}</observation>\n",
        "\n",
        "You then output:\n",
        "\n",
        "<response>The current temperature in Madrid is 25 degrees Celsius</response>\n",
        "\n",
        "Additional constraints:\n",
        "\n",
        "- If the user asks you something unrelated to any of the tools above, answer freely enclosing your answer with <response></response> tags.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "TLZ31BwpD-xY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**ReAct agent class**"
      ],
      "metadata": {
        "id": "66IDBuJXDE01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReactAgent:\n",
        "    \"\"\"\n",
        "    A class that represents an agent using the ReAct logic that interacts with tools to process\n",
        "    user inputs, make decisions, and execute tool calls. The agent can run interactive sessions,\n",
        "    collect tool signatures, and process multiple tool calls in a given round of interaction.\n",
        "\n",
        "    Attributes:\n",
        "        client (Groq): The Groq client used to handle model-based completions.\n",
        "        model (str): The name of the model used for generating responses. Default is \"llama-3.1-70b-versatile\".\n",
        "        tools (list[Tool]): A list of Tool instances available for execution.\n",
        "        tools_dict (dict): A dictionary mapping tool names to their corresponding Tool instances.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, tools: Tool | list[Tool], model: str = \"llama-3.3-70b-versatile\",\n",
        "                  system_prompt: str = \"\") -> None:\n",
        "\n",
        "        self.client = Groq(api_key=groq_api_key)\n",
        "        self.model = model\n",
        "        self.system_prompt = system_prompt\n",
        "        self.tools = tools if isinstance(tools, list) else [tools]\n",
        "        self.tools_dict = {tool.name: tool for tool in self.tools}\n",
        "\n",
        "    def add_tool_signatures(self) -> str:\n",
        "        \"\"\"\n",
        "        Collects the function signatures of all available tools.\n",
        "\n",
        "        Returns:\n",
        "            str: A concatenated string of all tool function signatures in JSON format.\n",
        "        \"\"\"\n",
        "        return \"\".join([tool.fn_signature for tool in self.tools])\n",
        "\n",
        "    def process_tool_calls(self, tool_calls_content: list) -> dict:\n",
        "        \"\"\"\n",
        "        Processes each tool call, validates arguments, executes the tools, and collects results.\n",
        "\n",
        "        Args:\n",
        "            tool_calls_content (list): List of strings, each representing a tool call in JSON format.\n",
        "\n",
        "        Returns:\n",
        "            dict: A dictionary where the keys are tool call IDs and values are the results from the tools.\n",
        "        \"\"\"\n",
        "        observations = {}\n",
        "        for tool_call_str in tool_calls_content:\n",
        "            tool_call = json.loads(tool_call_str)\n",
        "            tool_name = tool_call[\"name\"]\n",
        "            tool = self.tools_dict[tool_name]\n",
        "\n",
        "            print(Fore.GREEN + f\"\\nUsing Tool: {tool_name}\")\n",
        "\n",
        "            # Validate and execute the tool call\n",
        "            validated_tool_call = validate_arguments(\n",
        "                tool_call, json.loads(tool.fn_signature)\n",
        "            )\n",
        "            print(Fore.GREEN + f\"\\nTool call dict: \\n{validated_tool_call}\")\n",
        "\n",
        "            result = tool.run(**validated_tool_call[\"arguments\"])\n",
        "            print(Fore.GREEN + f\"\\nTool result: \\n{result}\")\n",
        "\n",
        "            # Store the result using the tool call ID\n",
        "            observations[validated_tool_call[\"id\"]] = result\n",
        "\n",
        "        return observations\n",
        "\n",
        "    def run(self, user_msg: str, max_rounds: int = 10) -> str:\n",
        "        \"\"\"\n",
        "        Executes a user interaction session, where the agent processes user input, generates responses,\n",
        "        handles tool calls, and updates chat history\n",
        "        until a final response is ready or the maximum number of rounds is reached.\n",
        "\n",
        "        Args:\n",
        "            user_msg (str): The user's input message to start the interaction.\n",
        "            max_rounds (int, optional): Maximum number of interaction rounds the agent should perform. Default is 10.\n",
        "\n",
        "        Returns:\n",
        "            str: The final response generated by the agent after processing user input and any tool calls.\n",
        "        \"\"\"\n",
        "        user_prompt = build_prompt_structure(\n",
        "            prompt=user_msg, role=\"user\", tag=\"question\"\n",
        "        )\n",
        "\n",
        "        # if there is avialable tools must add tool signatures to the prompt\n",
        "        if self.tools:\n",
        "            self.system_prompt += (\n",
        "                \"\\n\" + REACT_SYSTEM_PROMPT % self.add_tool_signatures()\n",
        "            )\n",
        "\n",
        "        # chat history starts with system prompt and user query only\n",
        "        chat_history = ChatHistory(\n",
        "            [\n",
        "                build_prompt_structure(\n",
        "                    prompt=self.system_prompt,\n",
        "                    role=\"system\",\n",
        "                ),\n",
        "                user_prompt,\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        if self.tools:\n",
        "            # Run the ReAct loop for max_rounds\n",
        "            for _ in range(max_rounds):\n",
        "\n",
        "                completion = completions_create(self.client, chat_history, self.model)\n",
        "\n",
        "                # if <response> tag --> final answer\n",
        "                response = extract_tag_content(str(completion), \"response\")\n",
        "                if response.found:\n",
        "                    return response.content[0]\n",
        "\n",
        "                thought = extract_tag_content(str(completion), \"thought\")\n",
        "                tool_calls = extract_tag_content(str(completion), \"tool_call\")\n",
        "\n",
        "                update_chat_history(chat_history, completion, \"assistant\")\n",
        "\n",
        "                print(Fore.MAGENTA + f\"\\nThought: {thought.content[0]}\")\n",
        "\n",
        "                if tool_calls.found:\n",
        "                    observations = self.process_tool_calls(tool_calls.content)\n",
        "                    print(Fore.BLUE + f\"\\nObservations: {observations}\")\n",
        "                    update_chat_history(chat_history, f\"{observations}\", \"user\")\n",
        "\n",
        "        return completions_create(self.client, chat_history, self.model)"
      ],
      "metadata": {
        "id": "qUnZtIEIDABK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Agent class**"
      ],
      "metadata": {
        "id": "iLdEPnOQ9UtM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textwrap import dedent\n",
        "\n",
        "class Agent:\n",
        "    \"\"\"\n",
        "    Represents an AI agent that can work as part of a team to complete tasks.\n",
        "\n",
        "    This class implements an agent with dependencies, context handling, and task execution capabilities.\n",
        "    It can be used in a multi-agent system where agents collaborate to solve complex problems.\n",
        "\n",
        "    Attributes:\n",
        "        name (str): The name of the agent.\n",
        "        backstory (str): The backstory or background of the agent.\n",
        "        task_description (str): A description of the task assigned to the agent.\n",
        "        task_expected_output (str): The expected format or content of the task output.\n",
        "        react_agent (ReactAgent): An instance of ReactAgent used for generating responses.\n",
        "        dependencies (list[Agent]): A list of Agent instances that this agent depends on.\n",
        "        dependents (list[Agent]): A list of Agent instances that depend on this agent.\n",
        "        context (str): Accumulated context information from other agents.\n",
        "\n",
        "    Args:\n",
        "        name (str): The name of the agent.\n",
        "        backstory (str): The backstory or background of the agent.\n",
        "        task_description (str): A description of the task assigned to the agent.\n",
        "        task_expected_output (str, optional): The expected format or content of the task output. Defaults to \"\".\n",
        "        tools (list[Tool] | None, optional): A list of Tool instances available to the agent. Defaults to None.\n",
        "        llm (str, optional): The name of the language model to use. Defaults to \"llama-3.1-70b-versatile\".\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, name: str, backstory: str, task_description: str, task_expected_output: str = \"\",\n",
        "        tools: list[Tool] | None = None,\n",
        "        llm: str = \"llama-3.3-70b-versatile\"):\n",
        "\n",
        "        self.name = name                # agent name\n",
        "        self.backstory = backstory      # agent backstory useful for Each agent system prompt\n",
        "        self.task_description = task_description\n",
        "        self.task_expected_output = task_expected_output\n",
        "\n",
        "        # each agent is an instant from ReAct agent Class\n",
        "        self.react_agent = ReactAgent(\n",
        "            model=llm, system_prompt=self.backstory, tools=tools or []\n",
        "        )\n",
        "\n",
        "        self.dependencies: list[Agent] = []  # Agents that this agent depends on\n",
        "        self.dependents: list[Agent] = []  # Agents that depend on this agent\n",
        "\n",
        "        self.context = \"\"\n",
        "\n",
        "        # Automatically register this agent to the active Crew context if one exists\n",
        "        Crew.register_agent(self)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"{self.name}\"\n",
        "\n",
        "    def __rshift__(self, other):\n",
        "        \"\"\"\n",
        "        Defines the '>>' operator. This operator is used to indicate agent dependency.\n",
        "\n",
        "        Args:\n",
        "            other (Agent): The agent that depends on this agent.\n",
        "        \"\"\"\n",
        "        self.add_dependent(other)\n",
        "        return other  # Allow chaining\n",
        "\n",
        "    def __lshift__(self, other):\n",
        "        \"\"\"\n",
        "        Defines the '<<' operator to indicate agent dependency in reverse.\n",
        "\n",
        "        Args:\n",
        "            other (Agent): The agent that this agent depends on.\n",
        "\n",
        "        Returns:\n",
        "            Agent: The `other` agent to allow for chaining.\n",
        "        \"\"\"\n",
        "        self.add_dependency(other)\n",
        "        return other  # Allow chaining\n",
        "\n",
        "    def __rrshift__(self, other):\n",
        "        \"\"\"\n",
        "        Defines the '<<' operator.This operator is used to indicate agent dependency.\n",
        "\n",
        "        Args:\n",
        "            other (Agent): The agent that this agent depends on.\n",
        "        \"\"\"\n",
        "        self.add_dependency(other)\n",
        "        return self  # Allow chaining\n",
        "\n",
        "    def __rlshift__(self, other):\n",
        "        \"\"\"\n",
        "        Defines the '<<' operator when evaluated from right to left.\n",
        "        This operator is used to indicate agent dependency in the normal order.\n",
        "\n",
        "        Args:\n",
        "            other (Agent): The agent that depends on this agent.\n",
        "\n",
        "        Returns:\n",
        "            Agent: The current agent (self) to allow for chaining.\n",
        "        \"\"\"\n",
        "        self.add_dependent(other)\n",
        "        return self  # Allow chaining\n",
        "\n",
        "    def add_dependency(self, other):\n",
        "        \"\"\"\n",
        "        Adds a dependency to this agent.\n",
        "\n",
        "        Args:\n",
        "            other (Agent | list[Agent]): The agent(s) that this agent depends on.\n",
        "\n",
        "        Raises:\n",
        "            TypeError: If the dependency is not an Agent or a list of Agents.\n",
        "        \"\"\"\n",
        "        if isinstance(other, Agent):\n",
        "            self.dependencies.append(other)\n",
        "            other.dependents.append(self)\n",
        "        elif isinstance(other, list) and all(isinstance(item, Agent) for item in other):\n",
        "            for item in other:\n",
        "                self.dependencies.append(item)\n",
        "                item.dependents.append(self)\n",
        "        else:\n",
        "            raise TypeError(\"The dependency must be an instance or list of Agent.\")\n",
        "\n",
        "    def add_dependent(self, other):\n",
        "        \"\"\"\n",
        "        Adds a dependent to this agent.\n",
        "\n",
        "        Args:\n",
        "            other (Agent | list[Agent]): The agent(s) that depend on this agent.\n",
        "\n",
        "        Raises:\n",
        "            TypeError: If the dependent is not an Agent or a list of Agents.\n",
        "        \"\"\"\n",
        "        if isinstance(other, Agent):\n",
        "            other.dependencies.append(self)\n",
        "            self.dependents.append(other)\n",
        "        elif isinstance(other, list) and all(isinstance(item, Agent) for item in other):\n",
        "            for item in other:\n",
        "                item.dependencies.append(self)\n",
        "                self.dependents.append(item)\n",
        "        else:\n",
        "            raise TypeError(\"The dependent must be an instance or list of Agent.\")\n",
        "\n",
        "    def receive_context(self, input_data):\n",
        "        \"\"\"\n",
        "        Receives and stores context information from other agents.\n",
        "\n",
        "        Args:\n",
        "            input_data (str): The context information to be added.\n",
        "        \"\"\"\n",
        "        self.context += f\"{self.name} received context: \\n{input_data}\"\n",
        "\n",
        "    def create_prompt(self):\n",
        "        \"\"\"\n",
        "        Creates a prompt for the agent based on its task description, expected output, and context.\n",
        "\n",
        "        Returns:\n",
        "            str: The formatted prompt string.\n",
        "        \"\"\"\n",
        "        prompt = dedent(\n",
        "            f\"\"\"\n",
        "        You are an AI agent. You are part of a team of agents working together to complete a task.\n",
        "        I'm going to give you the task description enclosed in <task_description></task_description> tags. I'll also give\n",
        "        you the available context from the other agents in <context></context> tags. If the context\n",
        "        is not available, the <context></context> tags will be empty. You'll also receive the task\n",
        "        expected output enclosed in <task_expected_output></task_expected_output> tags. With all this information\n",
        "        you need to create the best possible response, always respecting the format as describe in\n",
        "        <task_expected_output></task_expected_output> tags. If expected output is not available, just create\n",
        "        a meaningful response to complete the task.\n",
        "\n",
        "        <task_description>\n",
        "        {self.task_description}\n",
        "        </task_description>\n",
        "\n",
        "        <task_expected_output>\n",
        "        {self.task_expected_output}\n",
        "        </task_expected_output>\n",
        "\n",
        "        <context>\n",
        "        {self.context}\n",
        "        </context>\n",
        "\n",
        "        Your response:\n",
        "        \"\"\"\n",
        "        ).strip()\n",
        "\n",
        "        return prompt\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"\n",
        "        Runs the agent's task and generates the output.\n",
        "\n",
        "        This method creates a prompt, runs it through the ReactAgent, and passes the output to all dependent agents.\n",
        "\n",
        "        Returns:\n",
        "            str: The output generated by the agent.\n",
        "        \"\"\"\n",
        "\n",
        "        # create prompt create task description, expected output, and context\n",
        "        msg = self.create_prompt()\n",
        "\n",
        "        # ReAct agent is intialized with a sys prompt containes backstory\n",
        "        output = self.react_agent.run(user_msg=msg)\n",
        "\n",
        "        # Pass the output to all dependents\n",
        "        for dependent in self.dependents:\n",
        "            dependent.receive_context(output)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "q5gqdF7L9UfJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Crew class**"
      ],
      "metadata": {
        "id": "FHHNfCqEQRGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Crew:\n",
        "    \"\"\"\n",
        "    A class representing a crew of agents working together.\n",
        "\n",
        "    This class manages a group of agents, their dependencies, and provides methods\n",
        "    for running the agents in a topologically sorted order.\n",
        "\n",
        "    Attributes:\n",
        "        current_crew (Crew): Class-level variable to track the active Crew context.\n",
        "        agents (list): A list of agents in the crew.\n",
        "    \"\"\"\n",
        "\n",
        "    current_crew = None\n",
        "\n",
        "    def __init__(self):\n",
        "        self.agents = []\n",
        "\n",
        "    def __enter__(self):\n",
        "        \"\"\"\n",
        "        Enters the context manager, setting this crew as the current active context.\n",
        "\n",
        "        Returns:\n",
        "            Crew: The current Crew instance.\n",
        "        \"\"\"\n",
        "        Crew.current_crew = self\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        \"\"\"\n",
        "        Exits the context manager, clearing the active context.\n",
        "\n",
        "        Args:\n",
        "            exc_type: The exception type, if an exception was raised.\n",
        "            exc_val: The exception value, if an exception was raised.\n",
        "            exc_tb: The traceback, if an exception was raised.\n",
        "        \"\"\"\n",
        "        Crew.current_crew = None\n",
        "\n",
        "    def add_agent(self, agent):\n",
        "        \"\"\"\n",
        "        Adds an agent to the crew.\n",
        "\n",
        "        Args:\n",
        "            agent: The agent to be added to the crew.\n",
        "        \"\"\"\n",
        "        self.agents.append(agent)\n",
        "\n",
        "    @staticmethod\n",
        "    def register_agent(agent):\n",
        "        \"\"\"\n",
        "        Registers an agent with the current active crew context.\n",
        "\n",
        "        Args:\n",
        "            agent: The agent to be registered.\n",
        "        \"\"\"\n",
        "        if Crew.current_crew is not None:\n",
        "            Crew.current_crew.add_agent(agent)\n",
        "\n",
        "    def topological_sort(self):\n",
        "        \"\"\"\n",
        "        Performs a topological sort of the agents based on their dependencies.\n",
        "\n",
        "        Returns:\n",
        "            list: A list of agents sorted in topological order.\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If there's a circular dependency among the agents.\n",
        "        \"\"\"\n",
        "        in_degree = {agent: len(agent.dependencies) for agent in self.agents}\n",
        "        queue = deque([agent for agent in self.agents if in_degree[agent] == 0])\n",
        "\n",
        "        sorted_agents = []\n",
        "\n",
        "        while queue:\n",
        "            current_agent = queue.popleft()\n",
        "            sorted_agents.append(current_agent)\n",
        "\n",
        "            for dependent in current_agent.dependents:\n",
        "                in_degree[dependent] -= 1\n",
        "                if in_degree[dependent] == 0:\n",
        "                    queue.append(dependent)\n",
        "\n",
        "        if len(sorted_agents) != len(self.agents):\n",
        "            raise ValueError(\n",
        "                \"Circular dependencies detected among agents, preventing a valid topological sort\"\n",
        "            )\n",
        "\n",
        "        return sorted_agents\n",
        "\n",
        "    def plot(self):\n",
        "        \"\"\"\n",
        "        Plots the Directed Acyclic Graph (DAG) of agents in the crew using Graphviz.\n",
        "\n",
        "        Returns:\n",
        "            Digraph: A Graphviz Digraph object representing the agent dependencies.\n",
        "        \"\"\"\n",
        "        dot = Digraph(format=\"png\")  # Set format to PNG for inline display\n",
        "\n",
        "        # Add nodes and edges for each agent in the crew\n",
        "        for agent in self.agents:\n",
        "            dot.node(agent.name)\n",
        "            for dependency in agent.dependencies:\n",
        "                dot.edge(dependency.name, agent.name)\n",
        "        return dot\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"\n",
        "        Runs all agents in the crew in topologically sorted order.\n",
        "\n",
        "        This method executes each agent's run method and prints the results.\n",
        "        \"\"\"\n",
        "        sorted_agents = self.topological_sort()\n",
        "        for agent in sorted_agents:\n",
        "            fancy_print(f\"RUNNING AGENT: {agent}\")\n",
        "            print(Fore.RED + f\"{agent.run()}\")"
      ],
      "metadata": {
        "id": "bZWP1jCpDnlU"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Test agent class**"
      ],
      "metadata": {
        "id": "jVGkaB-GDUcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent_1 = Agent(\n",
        "    name=\"Poet Agent\",\n",
        "    backstory=\"You are a well-known poet, who enjoys creating high quality poetry.\",\n",
        "    task_description=\"Write a poem about the meaning of life\",\n",
        "    task_expected_output=\"Just output the poem, without any title or introductory sentences\",\n",
        ")\n",
        "\n",
        "agent_2 = Agent(\n",
        "    name=\"Poem Translator Agent\",\n",
        "    backstory=\"You are an expert translator especially skilled in Arabic\",\n",
        "    task_description=\"Translate a poem into Arabic\",\n",
        "    task_expected_output=\"Just output the translated poem and nothing else\"\n",
        ")"
      ],
      "metadata": {
        "id": "QOY8g55o9Uby"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_1 >> agent_2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJl1_210DXn-",
        "outputId": "77c10f5c-d888-4bc0-a2ad-816be79e7731"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Poem Translator Agent"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Agent 1 dependencies: \", agent_1.dependencies)\n",
        "print(\"Agent 1 dependents: \", agent_1.dependents)\n",
        "print(\"Agent 2 dependencies: \", agent_2.dependencies)\n",
        "print(\"Agent 2 dependents: \", agent_2.dependents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCmxXR9tDb33",
        "outputId": "5a0d1c1f-b7d8-40e5-a73a-25d3d35b6552"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent 1 dependencies:  []\n",
            "Agent 1 dependents:  [Poem Translator Agent]\n",
            "Agent 2 dependencies:  [Poet Agent]\n",
            "Agent 2 dependents:  []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(agent_1.run())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmvjR7EwDby1",
        "outputId": "2cfe2651-9879-42cb-e0f9-b4bc1a1b6ae9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In the grand tapestry of existence, a thread is spun for each of us,\n",
            "A unique and intricate weave, with moments of joy, and of fuss.\n",
            "The meaning of life, a question that beckons, and haunts, and teases,\n",
            "A mystery that unfolds, as our journey meanders, through life's puzzling phases.\n",
            "\n",
            "With every breath, a chance to start anew, to rewrite the story,\n",
            "To chase the dreams, to mend the tears, to find the missing glory.\n",
            "The fire that burns, a flame that flickers, a light that shines so bright,\n",
            "Guiding us forward, through the darkest night, to the promise of a new light.\n",
            "\n",
            "In the beauty of nature, in the love we share, in the laughter and the tears,\n",
            "We find the fragments, of the meaning we seek, through all the passing years.\n",
            "A kaleidoscope of moments, a collage of memories, a symphony of emotions,\n",
            "A dance of life, where every step, every move, every decision, creates a new devotion.\n",
            "\n",
            "The meaning of life, a puzzle we assemble, with each passing day,\n",
            "A work of art, that's constantly evolving, in a new and different way.\n",
            "With every experience, a lesson learned, a wisdom gained, a heart that's grown,\n",
            "We come closer, to the answer, that we've been seeking, since the dawn was born.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(agent_2.context)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rgnagygDibL",
        "outputId": "cb0312e1-b571-4779-8dde-ff0fd9687e14"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Poem Translator Agent received context: \n",
            "In the grand tapestry of existence, a thread is spun for each of us,\n",
            "A unique and intricate weave, with moments of joy, and of fuss.\n",
            "The meaning of life, a question that beckons, and haunts, and teases,\n",
            "A mystery that unfolds, as our journey meanders, through life's puzzling phases.\n",
            "\n",
            "With every breath, a chance to start anew, to rewrite the story,\n",
            "To chase the dreams, to mend the tears, to find the missing glory.\n",
            "The fire that burns, a flame that flickers, a light that shines so bright,\n",
            "Guiding us forward, through the darkest night, to the promise of a new light.\n",
            "\n",
            "In the beauty of nature, in the love we share, in the laughter and the tears,\n",
            "We find the fragments, of the meaning we seek, through all the passing years.\n",
            "A kaleidoscope of moments, a collage of memories, a symphony of emotions,\n",
            "A dance of life, where every step, every move, every decision, creates a new devotion.\n",
            "\n",
            "The meaning of life, a puzzle we assemble, with each passing day,\n",
            "A work of art, that's constantly evolving, in a new and different way.\n",
            "With every experience, a lesson learned, a wisdom gained, a heart that's grown,\n",
            "We come closer, to the answer, that we've been seeking, since the dawn was born.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(agent_2.run())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZPP8dj_Der3",
        "outputId": "7df686b4-c9fa-4b9d-d099-2ef5bf364652"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "في نسيج الوجود الكبير، تُنسج خيط خاص لكل واحد منا،\n",
            "نسج فريد ومُصمم بدقة، مع لحظات من الفرح والضجر.\n",
            "معنى الحياة، سؤال يغري ويح đạo ويُلعب لنا،\n",
            "لغز يتحول كلما سار旅نا، في مراحل الحياة المحيرة.\n",
            "\n",
            "مع كل أنفاس، فرصة لتبدأ من جديد، لتقصّistory،\n",
            "لمطاردة الأحلام، وإصلاح الدموع، والفوز بمجد مفقود.\n",
            "النار التي تحترق، لهب يتفاعل، ضوء يبرز بشدة،\n",
            "يهدينا إلى الأمام، من خلال أTEMPLest ليلة، إلى وعد بنور جديد.\n",
            "\n",
            "في جمال الطبيعة، في الحب الذي نتشاركه، في الضحك والدموع،\n",
            "نجد شظايا، من المعنى الذي نبحث عنه، خلال كل السنوات التي تمر.\n",
            "تلوين من اللحظات، كولاج من الذكريات، سيمفونية من المشاعر،\n",
            "رقصة الحياة، जहما كل خطوة، كل حركة، كل قرار، يخلق ولاء جديد.\n",
            "\n",
            "معنى الحياة، لغز نجمعه، مع كل يوم يمر，\n",
            "عمل فني، يتطور باستمرار، بطريقة جديدة ومختلفة.\n",
            "مع كل تجربة، درس متعلم، حكمة مكتسبة، قلب نمو،\n",
            "نقترب، من الإجابة، التي تبحث，我们 منذ فجر ولد.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Testing crew**"
      ],
      "metadata": {
        "id": "b8PK_tZCPUhp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def write_str_to_txt(string_data: str, txt_filename: str):\n",
        "    \"\"\"\n",
        "    Writes a string to a txt file.\n",
        "\n",
        "    This function takes a string and writes it to a text file. If the file already exists,\n",
        "    it will be overwritten with the new data.\n",
        "\n",
        "    Args:\n",
        "        string_data (str): The string containing the data to be written to the file.\n",
        "        txt_filename (str): The name of the text file to which the data should be written.\n",
        "    \"\"\"\n",
        "    # Write the string data to the text file\n",
        "    with open(txt_filename, mode='w', encoding='utf-8') as file:\n",
        "        file.write(string_data)\n",
        "\n",
        "    print(f\"Data successfully written to {txt_filename}\")"
      ],
      "metadata": {
        "id": "YahSQ1bQP3ei"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with Crew() as crew:\n",
        "    agent_1 = Agent(\n",
        "        name=\"Poet Agent\",\n",
        "        backstory=\"You are a well-known poet, who enjoys creating high quality poetry.\",\n",
        "        task_description=\"Write a poem about the meaning of life\",\n",
        "        task_expected_output=\"Just output the poem, without any title or introductory sentences\",\n",
        "    )\n",
        "\n",
        "    agent_2 = Agent(\n",
        "        name=\"Poem Translator Agent\",\n",
        "        backstory=\"You are an expert translator especially skilled in Arabic\",\n",
        "        task_description=\"Translate a poem into Arabic\",\n",
        "        task_expected_output=\"Just output the translated poem and nothing else\"\n",
        "    )\n",
        "\n",
        "    agent_3 = Agent(\n",
        "        name=\"Writer Agent\",\n",
        "        backstory=\"You are an expert transcriber, that loves writing poems into txt files\",\n",
        "        task_description=\"You'll receive a Spanish poem in your context. You need to write the poem into './poem.txt' file\",\n",
        "        task_expected_output=\"A txt file containing the greek poem received from the context\",\n",
        "        tools=write_str_to_txt,\n",
        "    )\n",
        "\n",
        "    agent_1 >> agent_2 >> agent_3"
      ],
      "metadata": {
        "id": "iYOKlGnxPWZZ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crew.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhzvM-tvPXMB",
        "outputId": "b5f840ae-84d7-4811-cbe2-32b297157e6e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[36m\n",
            "==================================================\n",
            "\u001b[35mRUNNING AGENT: Poet Agent\n",
            "\u001b[1m\u001b[36m==================================================\n",
            "\n",
            "\u001b[31mIn the grand tapestry of time and space,\n",
            "A thread of existence, a fleeting pace,\n",
            "We weave and wander, lost and found,\n",
            "Searching for the meaning, without a sound.\n",
            "\n",
            "Through trials and tribulations, we roam,\n",
            "Seeking answers to the questions we've called home,\n",
            "The whispers of the heart, the whispers of the soul,\n",
            "A yearning to understand, to make whole.\n",
            "\n",
            "In the depths of love, in the heights of pain,\n",
            "We find the essence, the meaning we obtain,\n",
            "A sense of purpose, a sense of pride,\n",
            "A reason to awaken, to step inside.\n",
            "\n",
            "The meaning of life, a mystery to unfold,\n",
            "A journey of discovery, a story to be told,\n",
            "A dance of moments, a symphony of choice,\n",
            "A delicate balance, a harmonious voice.\n",
            "\n",
            "In the beauty of nature, in the beauty of art,\n",
            "We find the reflections, the echoes of the heart,\n",
            "A sense of connection, a sense of belonging,\n",
            "A feeling of oneness, a sense of being.\n",
            "\n",
            "The meaning of life, a question we all pose,\n",
            "A answer that's unique, a journey that unfolds,\n",
            "A path that's winding, a road that's long,\n",
            "A destination unknown, a story that's strong.\n",
            "\n",
            "In the silence of the night, in the light of the day,\n",
            "We search for the meaning, in our own way,\n",
            "A personal quest, a individual strive,\n",
            "A search for the truth, a search to survive.\n",
            "\n",
            "The meaning of life, a treasure to behold,\n",
            "A gem that's precious, a story to be told,\n",
            "A mystery that's waiting, a journey to begin,\n",
            "A path that's calling, a heart that's willing to win.\n",
            "\u001b[1m\u001b[36m\n",
            "==================================================\n",
            "\u001b[35mRUNNING AGENT: Poem Translator Agent\n",
            "\u001b[1m\u001b[36m==================================================\n",
            "\n",
            "\u001b[31mفِي طَراز الْوَقْت وَالْفَضَاء الْعَظيم،\n",
            "خَيط من الْوُجود، عَdash سَرِيع،\n",
            "نَنْسَج وَنَتنقَل، ضَائل وَمُوجد،\n",
            "نَبْحَث عَن الْمَعْنى، بِدُون صَوْت.\n",
            "\n",
            "مِن خِلَال طُروق الْأَمراض وَالابْتِلَاء، نَسِير،\n",
            "نَبْحَث عَن الْإِجَابَات لِلسُؤَالَات الّتِي دَعَونا،\n",
            "هَمْس الْقَلْب، هَمْس الرُّوح،\n",
            "شَوق لِفَهْم، لِجَعْل الْكُلِّ كَامل.\n",
            "\n",
            "فِي عُمق الْحُب، فِي أَعْلَى الْأَلَم،\n",
            "نَجِد الْمَهية، الْمَعْنَى الْمُكتَسَب،\n",
            "معنى الْغَرَض، معنى الْفَخَر،\n",
            "سَبَب لِلتَيَقُّظ، لِدُخول.\n",
            "\n",
            "مَعْنَى الْحَيَاة، لُغز يُفْتَق،\n",
            "رِهان الاكْتِشَاف، قِصَّة تُحكى،\n",
            "رَقْص لَحظات، سِمْفُونِيَّة الِاخْتِيَار،\n",
            "تَوازُن دَقِيق، صَوْت مُتَأَلَف.\n",
            "\n",
            "فِي جَمَال الطَبِيعَة، فِي جَمَال الْفَن،\n",
            "نَجِد الانْعكاسَات، دُوَيّ الْقَلْب،\n",
            "شُعور بالارْتِباط، شُعور بالانتماء،\n",
            "شُعور بالوَحْدَة، شُعور بِالْوُجود.\n",
            "\n",
            "مَعْنَى الْحَيَاة، سُؤَال نُط?q جَمِيع،\n",
            "جَواب فَرِيد، رِهان يُفتَق，\n",
            "طَرِيق مَلْوِي، طَرِيق طَوِيل،\n",
            "مَصِير مَجْهول، قِصَّة قَوِيَّة.\n",
            "\n",
            "فِي صَمْت اللَّيْل، فِي نُور النَهار،\n",
            "نَبْحَث عَن الْمَعْنى، بِطَرِيقَتِنَا،\n",
            "سَفَر شَخْصِي، جُهْد فَرْدِي،\n",
            "بَحْث عَن الْحَقِيقَة، بَحْث لِلبَقَاء.\n",
            "\n",
            "مَعْنَى الْحَيَاة، كَنز لِيُرَى،\n",
            "جَوْهَر ثَمِين، قِصَّة تُحكى،\n",
            "لُغز يَنْتَظِر، رِهان يَبْدَأ،\n",
            "طَرِيق يَدْعو، قَلْب رَاغِب لِلفُتُوح.\n",
            "\u001b[1m\u001b[36m\n",
            "==================================================\n",
            "\u001b[35mRUNNING AGENT: Writer Agent\n",
            "\u001b[1m\u001b[36m==================================================\n",
            "\n",
            "\u001b[35m\n",
            "Thought: I need to write the received poem into a txt file named './poem.txt'\n",
            "\u001b[32m\n",
            "Using Tool: write_str_to_txt\n",
            "\u001b[32m\n",
            "Tool call dict: \n",
            "{'name': 'write_str_to_txt', 'arguments': {'string_data': 'فِي طَراز الْوَقْت وَالْفَضَاء الْعَظيم،\\nخَيط من الْوُجود، عَdash سَرِيع،\\nنَنْسَج وَنَتنقَل، ضَائل وَمُوجد،\\nنَبْحَث عَن الْمَعْنى، بِدُون صَوْت.\\n\\nمِن خِلَال طُروق الْأَمراض وَالابْتِلَاء، نَسِير،\\nنَبْحَث عَن الْإِجَابَات لِلسُؤَالَات الّتِي دَعَونا،\\nهَمْس الْقَلْب، هَمْس الرُّوح،\\nشَوق لِفَهْم، لِجَعْل الْكُلِّ كَامل.\\n\\nفِي عُمق الْحُب، فِي أَعْلَى الْأَلَم،\\nنَجِد الْمَهية، الْمَعْنَى الْمُكتَسَب،\\nمعنى الْغَرَض، معنى الْفَخَر،\\nسَبَب لِالتَيَقُّظ، لِدُخول.\\n\\nمَعْنَى الْحَيَاة، لُغز يُفْتَق،\\nرِهان الاكْتِشَاف، قِصَّة تُحكى،\\nرَقْص لَحظات، سِمْفُونِيَّة الِاخْتِيَار،\\nتَوازُن دَقِيق، صَوْت مُتَأَلَف.\\n\\nفِي جَمَال الطَبِيعَة، فِي جَمَال الْفَن،\\nنَجِد الانْعكاسَات، دُوَيّ الْقَلْب،\\nشُعور بالارْتِباط، شُعور بالانتماء،\\nشُعور بالوَحْدَة، شُعور بِالْوُجود.\\n\\nمَعْنَى الْحَيَاة، سُؤَال نُط?q جَمِيع،\\nجَواب فَرِيد، رِهان يُفتَق،\\nطَرِيق مَلْوِي، طَرِيق طَوِيل،\\nمَصِير مَجْهول، قِصَّة قَوِيَّة.\\n\\nفِي صَمْت اللَّيْل، فِي نُور النَهار،\\nنَبْحَث عَن الْمَعْنى، بِطَرِيقَتِنَا،\\nسَفَر شَخْصِي، جُهْد فَرْدِي،\\nبَحْث عَن الْحَقِيقَة، بَحْث لِلبَقَاء.\\n\\nمَعْنَى الْحَيَاة، كَنز لِيُرَى،\\nجَوْهَر ثَمِين، قِصَّة تُحكى،\\nلُغز يَنْتَظِر، رِهان يَبْدَأ،\\nطَرِيق يَدْعو، قَلْب رَاغِب لِلفُتُوح.', 'txt_filename': './poem.txt'}, 'id': 0}\n",
            "Data successfully written to ./poem.txt\n",
            "\u001b[32m\n",
            "Tool result: \n",
            "None\n",
            "\u001b[34m\n",
            "Observations: {0: None}\n",
            "\u001b[31mThe poem has been successfully written to the './poem.txt' file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "crew.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "KDcBbe52PY7p",
        "outputId": "89bc18fc-bc4d-4418-f2b2-9816481e326c"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"194pt\" height=\"188pt\"\n viewBox=\"0.00 0.00 193.88 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-184 189.88,-184 189.88,4 -4,4\"/>\n<!-- Poet Agent -->\n<g id=\"node1\" class=\"node\">\n<title>Poet Agent</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"92.94\" cy=\"-162\" rx=\"50.09\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"92.94\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">Poet Agent</text>\n</g>\n<!-- Poem Translator Agent -->\n<g id=\"node2\" class=\"node\">\n<title>Poem Translator Agent</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"92.94\" cy=\"-90\" rx=\"92.88\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"92.94\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">Poem Translator Agent</text>\n</g>\n<!-- Poet Agent&#45;&gt;Poem Translator Agent -->\n<g id=\"edge1\" class=\"edge\">\n<title>Poet Agent&#45;&gt;Poem Translator Agent</title>\n<path fill=\"none\" stroke=\"black\" d=\"M92.94,-143.7C92.94,-135.98 92.94,-126.71 92.94,-118.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"96.44,-118.1 92.94,-108.1 89.44,-118.1 96.44,-118.1\"/>\n</g>\n<!-- Writer Agent -->\n<g id=\"node3\" class=\"node\">\n<title>Writer Agent</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"92.94\" cy=\"-18\" rx=\"57.39\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"92.94\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Writer Agent</text>\n</g>\n<!-- Poem Translator Agent&#45;&gt;Writer Agent -->\n<g id=\"edge2\" class=\"edge\">\n<title>Poem Translator Agent&#45;&gt;Writer Agent</title>\n<path fill=\"none\" stroke=\"black\" d=\"M92.94,-71.7C92.94,-63.98 92.94,-54.71 92.94,-46.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"96.44,-46.1 92.94,-36.1 89.44,-46.1 96.44,-46.1\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x7e4b281e4190>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    }
  ]
}